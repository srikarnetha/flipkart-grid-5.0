# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nzx0LsYBEVsi20hgtth-UW_MP5K3QDYg
"""

!pip install -U scikit-learn
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten, Dropout
from tensorflow.keras.models import Model
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.pairwise import euclidean_distances!pip install -U scikit-learn
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten, Dropout
from tensorflow.keras.models import Model
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.pairwise import euclidean_distances!pip install -U scikit-learn
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten, Dropout
from tensorflow.keras.models import Model
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.pairwise import euclidean_distances!pip install -U scikit-learn
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten, Dropout
from tensorflow.keras.models import Model
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.pairwise import euclidean_distances

num_users = 1000
num_products = 500

user_profiles = {user_id: np.random.choice(['Electronics', 'Clothing', 'Beauty', 'Home'], size=2)
                 for user_id in range(1, num_users + 1)}

product_categories = ['Electronics', 'Clothing', 'Beauty', 'Home']
products = {f'prod{i}': {'product_name': f'Product {i}',
                         'category': np.random.choice(product_categories),
                         'popularity': np.random.uniform(0.1, 0.9)}
            for i in range(1, num_products + 1)}

interactions = {user_id: {f'prod{i}': np.random.randint(0, 2) for i in range(1, num_products + 1)}
                for user_id in range(1, num_users + 1)}num_users = 1000
num_products = 500

user_profiles = {user_id: np.random.choice(['Electronics', 'Clothing', 'Beauty', 'Home'], size=2)
                 for user_id in range(1, num_users + 1)}

product_categories = ['Electronics', 'Clothing', 'Beauty', 'Home']
products = {f'prod{i}': {'product_name': f'Product {i}',
                         'category': np.random.choice(product_categories),
                         'popularity': np.random.uniform(0.1, 0.9)}
            for i in range(1, num_products + 1)}

interactions = {user_id: {f'prod{i}': np.random.randint(0, 2) for i in range(1, num_products + 1)}
                for user_id in range(1, num_users + 1)}

user_profile_mapping = {category: idx for idx, category in enumerate(product_categories)}
user_profiles_encoded = {user_id: np.array([1 if category in user_profile else 0 for category in product_categories])
                         for user_id, user_profile in user_profiles.items()}

product_id_to_idx = {product_id: idx for idx, product_id in enumerate(products.keys())}
product_attributes = [product['popularity'] for product in products.values()]

# Combine user profiles and product attributes
X = np.array([(np.concatenate((user_profiles_encoded[user_id], [product_attributes[product_id_to_idx[product_id]]])))
              for user_id, user_interactions in interactions.items()
              for product_id, interaction_score in user_interactions.items() if interaction_score == 1])

# Interaction scores
y = np.array([interaction_score
              for user_interactions in interactions.values()
              for interaction_score in user_interactions.values() if interaction_score == 1])user_profile_mapping = {category: idx for idx, category in enumerate(product_categories)}
user_profiles_encoded = {user_id: np.array([1 if category in user_profile else 0 for category in product_categories])
                         for user_id, user_profile in user_profiles.items()}

product_id_to_idx = {product_id: idx for idx, product_id in enumerate(products.keys())}
product_attributes = [product['popularity'] for product in products.values()]

# Combine user profiles and product attributes
X = np.array([(np.concatenate((user_profiles_encoded[user_id], [product_attributes[product_id_to_idx[product_id]]])))
              for user_id, user_interactions in interactions.items()
              for product_id, interaction_score in user_interactions.items() if interaction_score == 1])

# Interaction scores
y = np.array([interaction_score
              for user_interactions in interactions.values()
              for interaction_score in user_interactions.values() if interaction_score == 1])user_profile_mapping = {category: idx for idx, category in enumerate(product_categories)}
user_profiles_encoded = {user_id: np.array([1 if category in user_profile else 0 for category in product_categories])
                         for user_id, user_profile in user_profiles.items()}

product_id_to_idx = {product_id: idx for idx, product_id in enumerate(products.keys())}
product_attributes = [product['popularity'] for product in products.values()]

# Combine user profiles and product attributes
X = np.array([(np.concatenate((user_profiles_encoded[user_id], [product_attributes[product_id_to_idx[product_id]]])))
              for user_id, user_interactions in interactions.items()
              for product_id, interaction_score in user_interactions.items() if interaction_score == 1])

# Interaction scores
y = np.array([interaction_score
              for user_interactions in interactions.values()
              for interaction_score in user_interactions.values() if interaction_score == 1])user_profile_mapping = {category: idx for idx, category in enumerate(product_categories)}
user_profiles_encoded = {user_id: np.array([1 if category in user_profile else 0 for category in product_categories])
                         for user_id, user_profile in user_profiles.items()}

product_id_to_idx = {product_id: idx for idx, product_id in enumerate(products.keys())}
product_attributes = [product['popularity'] for product in products.values()]

# Combine user profiles and product attributes
X = np.array([(np.concatenate((user_profiles_encoded[user_id], [product_attributes[product_id_to_idx[product_id]]])))
              for user_id, user_interactions in interactions.items()
              for product_id, interaction_score in user_interactions.items() if interaction_score == 1])

# Interaction scores
y = np.array([interaction_score
              for user_interactions in interactions.values()
              for interaction_score in user_interactions.values() if interaction_score == 1])

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

def build_hybrid_model(user_count, product_count, embedding_size=10):
    user_input = Input(shape=(1,))
    product_input = Input(shape=(1,))

    user_embedding = Embedding(user_count, embedding_size)(user_input)
    product_embedding = Embedding(product_count, embedding_size)(product_input)

    user_flatten = Flatten()(user_embedding)
    product_flatten = Flatten()(product_embedding)

    concat = Concatenate()([user_flatten, product_flatten])
    hidden = Dense(64, activation='relu')(concat)
    dropout = Dropout(0.2)(hidden)
    output = Dense(1, activation='sigmoid')(dropout)

    model = Model(inputs=[user_input, product_input], outputs=output)
    return modeldef build_hybrid_model(user_count, product_count, embedding_size=10):
    user_input = Input(shape=(1,))
    product_input = Input(shape=(1,))

    user_embedding = Embedding(user_count, embedding_size)(user_input)
    product_embedding = Embedding(product_count, embedding_size)(product_input)

    user_flatten = Flatten()(user_embedding)
    product_flatten = Flatten()(product_embedding)

    concat = Concatenate()([user_flatten, product_flatten])
    hidden = Dense(64, activation='relu')(concat)
    dropout = Dropout(0.2)(hidden)
    output = Dense(1, activation='sigmoid')(dropout)

    model = Model(inputs=[user_input, product_input], outputs=output)
    return model

user_count = num_users
product_count = num_products
embedding_size = 20

# Build the hybrid model (you should replace this with your actual model architecture)
hybrid_model = build_hybrid_model(user_count, product_count, embedding_size)
hybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the Hybrid model
hybrid_model.fit([X_train[:, 0], X_train[:, 1]], y_train, epochs=10, batch_size=64, validation_split=0.1)

# Get the user embeddings from the trained model

hybrid_model.summary()

user_count = num_users
product_count = num_products
embedding_size = 20

hybrid_model = build_hybrid_model(user_count, product_count, embedding_size)
hybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the Hybrid model
hybrid_model.fit([X_train[:, 0], X_train[:, 1]], y_train, epochs=10, batch_size=64, validation_split=0.1)

# Evaluate the model
loss, accuracy = hybrid_model.evaluate([X_test[:, 0], X_test[:, 1]], y_test)
print(f"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}")

hybrid_model.summary()

user_id = 1
user_profile = np.array(user_profiles[user_id])
product_attributes = [product['popularity'] for product in products.values()]
user_embedding_layer = hybrid_model.get_layer('embedding_12')
product_embedding_layer = hybrid_model.get_layer('embedding_13')

# Get the user embedding
user_embedding = user_embedding_layer(np.array([[user_id - 1]]))
user_embedding = user_embedding[0][0]

num_attributes = 20

# Calculate cosine similarity between user embedding and product attributes

user_embedding_np = user_embedding.numpy()  # Convert the EagerTensor to a NumPy array

# Convert product_attributes to a 2D numpy array
product_attributes_array = np.array(product_attributes)

user_embedding_reshaped = user_embedding_np.reshape(1, -1)

# Reshape product_attributes_array to be a 2D array
product_attributes_array_reshaped = product_attributes_array.reshape(-1, num_attributes)

# Calculate cosine similarity between user embedding and product attributes
similarities = cosine_similarity(user_embedding_reshaped, product_attributes_array_reshaped)

# Convert similarities array to 1D
similarities_1d = similarities.flatten()

# Rank products based on similarity
recommended_product_indices = np.argsort(similarities_1d)[::-1]

print("Recommended Products:")
for idx in recommended_product_indices[:10]:
    product_key = list(products.keys())[idx]  # Get the product key using the sorted index
    recommended_product_info = products[product_key]  # Get the product info using the product key
    recommended_product_name = recommended_product_info['product_name']
    print(f"Product ID: {product_key}, Product Name: {recommended_product_name}")user_id = 1
user_profile = np.array(user_profiles[user_id])
product_attributes = [product['popularity'] for product in products.values()]
user_embedding_layer = hybrid_model.get_layer('embedding_12')
product_embedding_layer = hybrid_model.get_layer('embedding_13')

# Get the user embedding
user_embedding = user_embedding_layer(np.array([[user_id - 1]]))
user_embedding = user_embedding[0][0]

num_attributes = 20

# Calculate cosine similarity between user embedding and product attributes

user_embedding_np = user_embedding.numpy()  # Convert the EagerTensor to a NumPy array

# Convert product_attributes to a 2D numpy array
product_attributes_array = np.array(product_attributes)

user_embedding_reshaped = user_embedding_np.reshape(1, -1)

# Reshape product_attributes_array to be a 2D array
product_attributes_array_reshaped = product_attributes_array.reshape(-1, num_attributes)

# Calculate cosine similarity between user embedding and product attributes
similarities = cosine_similarity(user_embedding_reshaped, product_attributes_array_reshaped)

# Convert similarities array to 1D
similarities_1d = similarities.flatten()

# Rank products based on similarity
recommended_product_indices = np.argsort(similarities_1d)[::-1]

print("Recommended Products:")
for idx in recommended_product_indices[:10]:
    product_key = list(products.keys())[idx]  # Get the product key using the sorted index
    recommended_product_info = products[product_key]  # Get the product info using the product key
    recommended_product_name = recommended_product_info['product_name']
    print(f"Product ID: {product_key}, Product Name: {recommended_product_name}")

best_accuracy = 0.0
best_model = None

# Train the model
hybrid_model.fit([X_train[:, 0], X_train[:, 1]], y_train, epochs=10, batch_size=64, validation_split=0.1)

# Evaluate the model
loss, accuracy = hybrid_model.evaluate([X_test[:, 0], X_test[:, 1]], y_test)

if accuracy > best_accuracy:
    best_accuracy = accuracy
    best_model = hybrid_model

print(f"Test Accuracy: {accuracy:.4f}")

if best_model is not None:
    print("Best Model's Test Accuracy:", best_accuracy)

y_pred = hybrid_model.predict([X_test[:, 0], X_test[:, 1]])
y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions

accuracy = np.mean(y_pred_binary == y_test)
print(f"Test Accuracy: {accuracy:.4f}")y_pred = hybrid_model.predict([X_test[:, 0], X_test[:, 1]])
y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions

accuracy = np.mean(y_pred_binary == y_test)
print(f"Test Accuracy: {accuracy:.4f}")